{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "\n",
    "import numpy, pandas, scipy, scipy.special\n",
    "from frozendict import frozendict\n",
    "\n",
    "import collections, functools, itertools, math, typing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12953, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GUESSABLE_WORDS_FILE = './allowed_guesses.txt'\n",
    "\n",
    "guessable_words = sorted(\n",
    "    line.strip() for line in open(GUESSABLE_WORDS_FILE, 'r').readlines())\n",
    "\n",
    "TARGET_LENGTH = len(guessable_words[0])\n",
    "\n",
    "len(guessable_words), TARGET_LENGTH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>about</td>\n",
       "      <td>1226734006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>other</td>\n",
       "      <td>978481319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>which</td>\n",
       "      <td>810514085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>their</td>\n",
       "      <td>782849411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>there</td>\n",
       "      <td>701170205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331059</th>\n",
       "      <td>sadis</td>\n",
       "      <td>12774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331869</th>\n",
       "      <td>maist</td>\n",
       "      <td>12738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331922</th>\n",
       "      <td>hully</td>\n",
       "      <td>12736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332433</th>\n",
       "      <td>intil</td>\n",
       "      <td>12721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332682</th>\n",
       "      <td>toits</td>\n",
       "      <td>12716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8078 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word       count\n",
       "35      about  1226734006\n",
       "45      other   978481319\n",
       "56      which   810514085\n",
       "57      their   782849411\n",
       "62      there   701170205\n",
       "...       ...         ...\n",
       "331059  sadis       12774\n",
       "331869  maist       12738\n",
       "331922  hully       12736\n",
       "332433  intil       12721\n",
       "332682  toits       12716\n",
       "\n",
       "[8078 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNIGRAM_FREQUENCIES_FILE = './useful_stats/unigram_freq.csv'\n",
    "\n",
    "unigram_frequencies_df = pandas.read_csv(UNIGRAM_FREQUENCIES_FILE,\n",
    "                                         keep_default_na=False)\n",
    "guessable_words_frequencies_df = unigram_frequencies_df[\n",
    "    unigram_frequencies_df['word'].isin(guessable_words)]\n",
    "\n",
    "unigram_frequencies: frozendict[str, int] = frozendict(\n",
    "    unigram_frequencies_df.set_index('word')['count'].to_dict())\n",
    "\n",
    "guessable_words_frequencies_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target='melee'\n",
      "guess='quest' is_word_fitting(clues, guess)=True\n",
      "clues=frozendict.frozendict({'e': LetterClue(min_count=1, bounded=False, in_positions=frozenset(), not_in_positions=frozenset({2})), 'q': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 't': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'u': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 's': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset())})\n",
      "guess='panel' is_word_fitting(clues, guess)=True\n",
      "clues=frozendict.frozendict({'e': LetterClue(min_count=1, bounded=False, in_positions=frozenset({3}), not_in_positions=frozenset({2})), 'q': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 't': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'u': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 's': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'n': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'l': LetterClue(min_count=1, bounded=False, in_positions=frozenset(), not_in_positions=frozenset({4})), 'p': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'a': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset())})\n",
      "guess='elder' is_word_fitting(clues, guess)=True\n",
      "clues=frozendict.frozendict({'e': LetterClue(min_count=2, bounded=False, in_positions=frozenset({3}), not_in_positions=frozenset({0, 2})), 'q': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 't': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'u': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 's': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'n': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'l': LetterClue(min_count=1, bounded=False, in_positions=frozenset(), not_in_positions=frozenset({1, 4})), 'p': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'a': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'r': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'd': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset())})\n",
      "guess='levee' is_word_fitting(clues, guess)=True\n",
      "clues=frozendict.frozendict({'e': LetterClue(min_count=3, bounded=False, in_positions=frozenset({1, 3, 4}), not_in_positions=frozenset({0, 2})), 'q': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 't': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'u': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 's': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'n': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'l': LetterClue(min_count=1, bounded=False, in_positions=frozenset(), not_in_positions=frozenset({0, 1, 4})), 'p': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'a': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'r': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'd': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset()), 'v': LetterClue(min_count=0, bounded=True, in_positions=frozenset(), not_in_positions=frozenset())})\n"
     ]
    }
   ],
   "source": [
    "class LetterClue(typing.NamedTuple):\n",
    "    min_count: int\n",
    "    bounded: bool\n",
    "    in_positions: frozenset[int]\n",
    "    not_in_positions: frozenset[int]\n",
    "\n",
    "\n",
    "Clues = frozendict[str, LetterClue]\n",
    "\n",
    "\n",
    "def judge(target: str, guess: str) -> Clues:\n",
    "    clues: dict[str, LetterClue] = {}\n",
    "    for letter in set(guess):\n",
    "        min_count = min(guess.count(letter), target.count(letter))\n",
    "        bounded = guess.count(letter) > target.count(letter)\n",
    "        positions_in_guess = {i for i, l in enumerate(guess) if l == letter}\n",
    "        positions_in_target = {i for i, l in enumerate(target) if l == letter}\n",
    "        in_positions = positions_in_guess & positions_in_target\n",
    "        if bounded and len(in_positions) == min_count:\n",
    "            not_in_positions = set()\n",
    "        else:\n",
    "            not_in_positions = positions_in_guess - positions_in_target\n",
    "        clues[letter] = LetterClue(min_count, bounded, frozenset(in_positions),\n",
    "                                   frozenset(not_in_positions))\n",
    "    return frozendict(clues)\n",
    "\n",
    "\n",
    "def combine_clues(c1: Clues, c2: Clues) -> Clues:\n",
    "    combined_clues = dict(c1)\n",
    "    for letter, new_clues in c2.items():\n",
    "        if letter not in combined_clues:\n",
    "            combined_clues[letter] = new_clues\n",
    "        else:\n",
    "            old_clues = combined_clues[letter]\n",
    "            min_count = max(old_clues.min_count, new_clues.min_count)\n",
    "            bounded = old_clues.bounded or new_clues.bounded\n",
    "            if bounded:\n",
    "                assert old_clues.min_count == new_clues.min_count\n",
    "            in_positions = old_clues.in_positions | new_clues.in_positions\n",
    "            if bounded and len(in_positions) == min_count:\n",
    "                not_in_positions = frozenset()\n",
    "            else:\n",
    "                not_in_positions = frozenset(old_clues.not_in_positions\n",
    "                                             | new_clues.not_in_positions)\n",
    "            combined_clues[letter] = LetterClue(min_count, bounded,\n",
    "                                                in_positions, not_in_positions)\n",
    "    return frozendict(combined_clues)\n",
    "\n",
    "\n",
    "def is_word_fitting(clues: Clues, word: str, *, hard_mode=False) -> bool:\n",
    "    for letter, clue in clues.items():\n",
    "        if word.count(letter) < clue.min_count:\n",
    "            return False\n",
    "        if not all(word[i] == letter for i in clue.in_positions):\n",
    "            return False\n",
    "        if not hard_mode:\n",
    "            if clue.bounded and word.count(letter) > clue.min_count:\n",
    "                return False\n",
    "            if any(word[i] == letter for i in clue.not_in_positions):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def gen_fitting_words(\n",
    "        clues: Clues,\n",
    "        candidate_words: typing.Iterable[str]) -> typing.Iterator[str]:\n",
    "    for word in candidate_words:\n",
    "        if is_word_fitting(clues, word): yield word\n",
    "\n",
    "\n",
    "# Example:\n",
    "target = 'melee'\n",
    "clues = Clues()\n",
    "print(f'{target=}')\n",
    "guess = 'quest'\n",
    "print(f'{guess=} {is_word_fitting(clues, guess)=}')\n",
    "clues = combine_clues(clues, judge(target, guess))\n",
    "print(f'{clues=}')  # --^--\n",
    "guess = 'panel'\n",
    "print(f'{guess=} {is_word_fitting(clues, guess)=}')\n",
    "clues = combine_clues(clues, judge(target, guess))\n",
    "print(f'{clues=}')  # ---#^\n",
    "guess = 'elder'\n",
    "print(f'{guess=} {is_word_fitting(clues, guess)=}')\n",
    "clues = combine_clues(clues, judge(target, guess))\n",
    "print(f'{clues=}')  # ^^-#-\n",
    "guess = 'levee'\n",
    "print(f'{guess=} {is_word_fitting(clues, guess)=}')\n",
    "clues = combine_clues(clues, judge(target, guess))\n",
    "print(f'{clues=}')  # ^#-##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False, True, True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trivial_plurals = set()\n",
    "for word in guessable_words:\n",
    "    if not word.endswith('s') or word.endswith('ss'): continue\n",
    "    base = word[:-1]\n",
    "    if (unigram_frequencies.get(base, 0) <=\n",
    "            0.5 * unigram_frequencies.get(word, 0)):\n",
    "        # Assume that any word is always \"around as common as\" its trivial plural. This is to filter out stuff like \"oasis\" from being a trivial plural, where \"oasi\" is also in the dictionary somehow.\n",
    "        continue\n",
    "    trivial_plurals.add(word)\n",
    "\n",
    "'oasis' in trivial_plurals, 'bonus' in trivial_plurals, 'gears' in trivial_plurals, 'sofas' in trivial_plurals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(set(), 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OFFENSIVE_WORDS_FILE = './useful_stats/offensive_words.txt'\n",
    "\n",
    "# I had a surprisingly difficult time finding a good list for these. The list in the current file also includes fairly normal words like \"spook\" which I don't see why couldn't be a real Wordle answer. For now this list is unused.\n",
    "\n",
    "offensive_words = set()\n",
    "# alphabet = set(itertools.chain(*guessable_words))\n",
    "# for line in open(OFFENSIVE_WORDS_FILE, 'r').readlines():\n",
    "#     line = line.strip()\n",
    "#     if len(line) != TARGET_LENGTH: continue\n",
    "#     if any(c not in alphabet for c in line): continue\n",
    "#     offensive_words.add(line)\n",
    "\n",
    "offensive_words, len(offensive_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('music', 1.0, 1.0),\n",
       "  ('scene', 1.0, 1.0),\n",
       "  ('screw', 1.0, 0.9999999277517385),\n",
       "  ('since', 1.0, 1.0),\n",
       "  ('specs', 1.0, 1.0),\n",
       "  ('spice', 1.0, 0.9999989850650284),\n",
       "  ('slice', 0.9999999999994293, 0.9994855756537293),\n",
       "  ('spicy', 0.9999999905013234, 0.9806788085967384),\n",
       "  ('hicks', 0.9999991872704823, 0.9053876348115549),\n",
       "  ('slick', 0.9999980562574173, 0.8734247516346668),\n",
       "  ('scrub', 0.9999978896613175, 0.8699761044913237),\n",
       "  ('psych', 0.9989085760072909, 0.3910722019058516),\n",
       "  ('speck', 0.9157853674908787, 0.10860259956113578),\n",
       "  ('feces', 0.8314968874123442, 0.08306619219055851),\n",
       "  ('synch', 0.7956730034022881, 0.07654805846378952),\n",
       "  ('mucus', 0.7919049897404956, 0.07594006665008601),\n",
       "  ('sucre', 0.7557060011706569, 0.0706649261715832),\n",
       "  ('scrum', 0.5430101090651521, 0.050434693807072876),\n",
       "  ('scrip', 0.38355328475759504, 0.04000456333479656),\n",
       "  ('ficus', 0.3084121104473478, 0.03547414559351664),\n",
       "  ('snuck', 0.30223025699759926, 0.035102060537835315),\n",
       "  ('scuff', 0.23706351796020658, 0.031119172830201554),\n",
       "  ('sucky', 0.211080174240595, 0.029471702332372986),\n",
       "  ('scull', 0.1815501797533658, 0.027526196141774168),\n",
       "  ('scree', 0.1574453649458352, 0.025856162568433854),\n",
       "  ('scrim', 0.1561066539356239, 0.025760684604729602),\n",
       "  ('mesic', 0.14335084832413902, 0.024833855445609135),\n",
       "  ('disci', 0.14330009790142256, 0.02483010206612013),\n",
       "  ('shuck', 0.13108720277877445, 0.023909778609251267),\n",
       "  ('fucus', 0.091185370975931, 0.020588534554001864),\n",
       "  ('schul', 0.07970465415037269, 0.019504984762052265),\n",
       "  ('misch', 0.0784188382473064, 0.019378734692722645),\n",
       "  ('sculp', 0.07778522294297542, 0.01931612349623785),\n",
       "  ('snick', 0.07498096738285225, 0.019035744889731008),\n",
       "  ('sulci', 0.07417074689562457, 0.018953709149600435),\n",
       "  ('scurf', 0.07064566498842338, 0.018591122272472397),\n",
       "  ('succi', 0.07053457023082452, 0.018579539925820197)],\n",
       " 37,\n",
       " 18)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@functools.cache\n",
    "def target_probability(word: str) -> float:\n",
    "    if word in trivial_plurals or word in offensive_words: return 0.0\n",
    "    if word not in unigram_frequencies: return 0.0\n",
    "    return scipy.special.expit((unigram_frequencies[word] - 4E5) / 1.5E5)\n",
    "\n",
    "@functools.cache\n",
    "def familiar_probability(word: str) -> float:\n",
    "    if word in trivial_plurals or word in offensive_words: return 0.0\n",
    "    if word not in unigram_frequencies: return 0.0\n",
    "    return scipy.special.expit((unigram_frequencies[word] - 16E5) / 4E5)\n",
    "\n",
    "target = 'spice'\n",
    "guesses = ['coast']\n",
    "# target = 'scrub'\n",
    "# guesses = ['roach']\n",
    "\n",
    "clues = Clues()\n",
    "for guess in guesses:\n",
    "    clues = combine_clues(clues, judge(target, guess))\n",
    "candidates = []\n",
    "for word in gen_fitting_words(clues, guessable_words):\n",
    "    p = target_probability(word)\n",
    "    if p > 0: candidates.append((word, p, familiar_probability(word)))\n",
    "candidates.sort(reverse=True, key=lambda x: x[1])\n",
    "candidates, len(candidates), sum(x[1] > 0.5 for x in candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
